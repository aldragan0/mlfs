{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional, cast, Callable\n",
    "from numbers import Number\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature: str | int | None = None,\n",
    "        value: Optional[object] = None,\n",
    "        left: Optional[Node] = None,\n",
    "        right: Optional[Node] = None\n",
    "    ) -> None:\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.f = feature\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"{{f: {}, v: {}, left: {}, right: {}}}\".format(self.f, self.value, self.left, self.right)\n",
    "\n",
    "\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, root: Node, verbose: bool = False) -> None:\n",
    "        self.root = root\n",
    "        self.__verbose = verbose\n",
    "\n",
    "\n",
    "    def __debug(self, value = None) -> None:\n",
    "        if self.__verbose:\n",
    "            print(value)\n",
    "\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> object:\n",
    "        self.__debug(f\"predicting for input: {x}\")\n",
    "        curr = self.root\n",
    "        \n",
    "        while curr.f is not None:\n",
    "            self.__debug(f'feature: {curr.f}, value: {curr.value}')\n",
    "            if x[curr.f] >= curr.value:\n",
    "                curr = curr.left\n",
    "            else:\n",
    "                curr = curr.right\n",
    "            curr = cast(Node, curr)\n",
    "        \n",
    "        self.__debug()\n",
    "        return curr.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1, 1, 1],\n",
    "[0, 0, 1],\n",
    " [0, 1, 0],\n",
    " [1, 0, 1],\n",
    " [1, 1, 1],\n",
    " [1, 1, 0],\n",
    " [0, 0, 0],\n",
    " [1, 1, 0],\n",
    " [0, 1, 0],\n",
    " [0, 1, 0]])\n",
    "\n",
    "y_train = np.array([1, 1, 0, 0, 1, 1, 0, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTree(\n",
    "    Node(\n",
    "        feature=0,\n",
    "        value=1,\n",
    "        left=Node(\n",
    "            feature=1,\n",
    "            value=1,\n",
    "            left=Node(\n",
    "                value=1\n",
    "            ),\n",
    "            right=Node(\n",
    "                value=0\n",
    "            )\n",
    "        ),\n",
    "        right=Node(\n",
    "            feature=2,\n",
    "            value=1,\n",
    "            left=Node(\n",
    "                value=1\n",
    "            ),\n",
    "            right=Node(\n",
    "                value=0\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = [tree.predict(X_train[i]) for i in range(X_train.shape[0])]\n",
    "y_train - y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y: float) -> float:\n",
    "    if y == 0 or y == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return -y * np.log2(y) - (1 - y) * np.log2(1 - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.4689955935892812\n",
      "0.7219280948873623\n",
      "0.8812908992306927\n",
      "0.9709505944546686\n",
      "1.0\n",
      "0.9709505944546686\n",
      "0.8812908992306926\n",
      "0.7219280948873623\n",
      "0.4689955935892811\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0, 1.1, .1):\n",
    "    print(entropy(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(left_idx: np.ndarray, right_idx: np.ndarray, parent_idx: np.ndarray, y: np.ndarray) -> float:\n",
    "    parent_y = y[parent_idx]\n",
    "    p_root = np.sum(parent_y) / parent_y.shape[0]\n",
    "\n",
    "    left = y[left_idx]\n",
    "\n",
    "    w_left = len(left) / len(y)\n",
    "    p_left = np.sum(left) / (len(left) + 1e-15)\n",
    "\n",
    "    right = y[right_idx]\n",
    "\n",
    "    w_right = len(right) / len(y)\n",
    "    p_right = np.sum(right) / (len(right) + 1e-15)\n",
    "\n",
    "    return inf_gain(p_root, p_left, w_left, p_right, w_right)\n",
    "\n",
    "def inf_gain(p_root: float, p_left: float, w_left: float, p_right: float, w_right: float) -> float:\n",
    "    return entropy(p_root) - (w_left * entropy(p_left) + w_right * entropy(p_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2780719051126377"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_gain(.5, 4/5, .5, 1/5, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_feature(X: np.ndarray, idx: np.ndarray, feature: str | int, value: Number) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    left_mask = X[idx, feature] >= value\n",
    "    right_mask = ~left_mask\n",
    "\n",
    "    return idx[left_mask], idx[right_mask]\n",
    "\n",
    "def get_best_feature_idx(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    cost_fn: Callable[[np.ndarray, np.ndarray, np.ndarray, np.ndarray], float],\n",
    "    idx: np.ndarray,\n",
    "    features: Dict[str | int, List[Number]],\n",
    "    feature_keys: List[str | int]\n",
    ") -> Tuple[str | int, int, float]:\n",
    "\n",
    "    costs: List[Tuple[str | int, int, float]] = []\n",
    "\n",
    "    for feature_key in feature_keys:\n",
    "        for i, value in enumerate(features[feature_key]):\n",
    "            left_idx, right_idx = split_by_feature(X, idx, feature_key, value)\n",
    "\n",
    "            cost = cost_fn(left_idx, right_idx, idx, y)\n",
    "            costs.append((feature_key, i, cost))\n",
    "    \n",
    "    return max(costs, key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first level feature: 0:0, inf gain: 0.27807190511263746\n",
      "[0 3 4 5 7]\n",
      "[1 2 6 8 9]\n",
      "second level left feature: 1:0, inf gain: 0.7219280948873575\n",
      "[0 4 5 7]\n",
      "[3]\n",
      "second level right feature: 2:0, inf gain: 0.7219280948873567\n",
      "[1]\n",
      "[2 6 8 9]\n"
     ]
    }
   ],
   "source": [
    "features: Dict[str | int, List[Number]] = {i:[1] for i in range(X_train.shape[1])}\n",
    "feature_keys = list(features.keys())\n",
    "\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "idx = np.arange(X.shape[0])\n",
    "\n",
    "fkey, f_idx, cost_decrease = get_best_feature_idx(X, y, information_gain, idx, features, feature_keys)\n",
    "print(f'first level feature: {fkey}:{f_idx}, inf gain: {cost_decrease}')\n",
    "\n",
    "left_idx, right_idx = split_by_feature(X, idx, fkey, features[fkey][f_idx])\n",
    "print(left_idx)\n",
    "print(right_idx)\n",
    "\n",
    "left_fkey, left_f_idx, cost_decrease = get_best_feature_idx(X, y, information_gain, left_idx, features, feature_keys)\n",
    "print(f'second level left feature: {left_fkey}:{left_f_idx}, inf gain: {cost_decrease}')\n",
    "\n",
    "left_left_idx, left_right_idx = split_by_feature(X, left_idx, left_fkey, features[left_fkey][left_f_idx])\n",
    "print(left_left_idx)\n",
    "print(left_right_idx)\n",
    "\n",
    "right_fkey, right_f_idx, cost_decrease = get_best_feature_idx(X, y, information_gain, right_idx, features, feature_keys)\n",
    "print(f'second level right feature: {right_fkey}:{right_f_idx}, inf gain: {cost_decrease}')\n",
    "\n",
    "right_left_idx, right_right_idx = split_by_feature(X, right_idx, right_fkey, features[right_fkey][right_f_idx])\n",
    "print(right_left_idx)\n",
    "print(right_right_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_categorical(unique_feature_vals: np.ndarray) -> bool:\n",
    "    return np.max(unique_feature_vals) == 1 and np.min(unique_feature_vals) == 0 and len(unique_feature_vals) == 2\n",
    "\n",
    "\n",
    "def make_continuous_decision_boundaries(unique_feature_vals: np.ndarray) -> np.ndarray:\n",
    "    return (unique_feature_vals[:-1] + unique_feature_vals[1:]) / 2\n",
    "\n",
    "\n",
    "def make_features(X: np.ndarray) -> Dict[str | int, List[Number]]:\n",
    "    features = dict()\n",
    "\n",
    "    for feature in range(X.shape[1]):\n",
    "        unique_fvals = np.unique(X[:, feature])\n",
    "        \n",
    "        if is_categorical(unique_fvals):\n",
    "            features[feature] = [1]\n",
    "        else:\n",
    "            features[feature] = make_continuous_decision_boundaries(unique_fvals)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def build_tree(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    cost_fn: Callable[[np.ndarray, np.ndarray, np.ndarray, np.ndarray], float],\n",
    "    compute_leaf: Callable[[np.ndarray], np.number],\n",
    "    max_height: int,\n",
    "    inf_gain_threshold: float = 1e-15,\n",
    "    min_sample_count: int = 1,\n",
    "    num_features: int | None = None,\n",
    "    rng_seed: int | None = None\n",
    ") -> DecisionTree:\n",
    "    num_features = X.shape[1] if num_features is None else min(num_features, X.shape[1])\n",
    "    random.seed(rng_seed)\n",
    "\n",
    "    features = make_features(X)\n",
    "    feature_keys = list(features.keys())\n",
    "\n",
    "    idx = np.arange(X.shape[0])\n",
    "    root = Node()\n",
    "    \n",
    "    queue: deque[Tuple[np.ndarray, Node, int]] = deque([(idx, root, 0)])\n",
    "    \n",
    "    while len(queue) > 0:\n",
    "        idx, node, height = queue.popleft()\n",
    "\n",
    "        if num_features < X.shape[1]:\n",
    "            keys = random.sample(feature_keys, k=num_features)\n",
    "        else:\n",
    "            keys = feature_keys\n",
    "\n",
    "        best_fkey, best_f_idx, max_inf_gain = get_best_feature_idx(X, y, cost_fn, idx, features, keys)\n",
    "\n",
    "        # If stopping criteria is met\n",
    "        if height == max_height\\\n",
    "        or idx.shape[0] <= min_sample_count\\\n",
    "        or max_inf_gain <= inf_gain_threshold:\n",
    "            # Set the leaf node to be the dominant class\n",
    "            node.value = compute_leaf(y[idx])\n",
    "            continue\n",
    "\n",
    "        # Update the node with the best feature\n",
    "        fval = features[best_fkey][best_f_idx]\n",
    "        node.f = best_fkey\n",
    "        node.value = fval\n",
    "        node.left = Node()\n",
    "        node.right = Node()\n",
    "\n",
    "        # Create the children nodes\n",
    "        left_idx, right_idx = split_by_feature(X, idx, node.f, node.value)\n",
    "\n",
    "        queue.append((left_idx, node.left, height + 1))\n",
    "        queue.append((right_idx, node.right, height + 1))\n",
    "    \n",
    "    return DecisionTree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dominant_class(y: np.ndarray) -> np.integer:\n",
    "    return np.argmax(np.bincount(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = build_tree(X_train, y_train, information_gain, get_dominant_class, 2)\n",
    "\n",
    "tree.predict(X_train[0])\n",
    "y_hat = [tree.predict(X_train[i]) for i in range(X_train.shape[0])]\n",
    "y_train - y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed = np.random.default_rng(seed=0)\n",
    "\n",
    "test_x = rng_seed.random(size=(20, 2))\n",
    "test_y = (np.average(test_x, axis=1) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63696169 0.26978671]\n",
      " [0.04097352 0.01652764]\n",
      " [0.81327024 0.91275558]\n",
      " [0.60663578 0.72949656]\n",
      " [0.54362499 0.93507242]\n",
      " [0.81585355 0.0027385 ]\n",
      " [0.85740428 0.03358558]\n",
      " [0.72965545 0.17565562]\n",
      " [0.86317892 0.54146122]\n",
      " [0.29971189 0.42268722]\n",
      " [0.02831967 0.12428328]\n",
      " [0.67062441 0.64718951]\n",
      " [0.61538511 0.38367755]\n",
      " [0.99720994 0.98083534]\n",
      " [0.68554198 0.65045928]\n",
      " [0.68844673 0.38892142]\n",
      " [0.13509651 0.72148834]\n",
      " [0.52535432 0.31024188]\n",
      " [0.48583536 0.88948783]\n",
      " [0.93404352 0.3577952 ]]\n",
      "[0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_x)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree = build_tree(test_x, test_y, information_gain, get_dominant_class, max_height=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{f: 1, v: 0.33401853613401294, left: {f: 0, v: 0.39277362468458693, left: {f: None, v: 1, left: None, right: None}, right: {f: None, v: 0, left: None, right: None}}, right: {f: None, v: 0, left: None, right: None}}\n"
     ]
    }
   ],
   "source": [
    "print(test_tree.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_hat = [test_tree.predict(test_x[i]) for i in range(test_x.shape[0])]\n",
    "print(y_hat - test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "def variance_gain(left_idx: np.ndarray, right_idx: np.ndarray, parent_idx: np.ndarray, y: np.ndarray) -> float:\n",
    "    parent_y = y[parent_idx]\n",
    "    parent_var = np.var(parent_y)\n",
    "\n",
    "    left = y[left_idx]\n",
    "\n",
    "    w_left = len(left) / len(y)\n",
    "    left_var = np.var(left) if len(left) > 0 else 0.0\n",
    "\n",
    "    right = y[right_idx]\n",
    "\n",
    "    w_right = len(right) / len(y)\n",
    "    right_var = np.var(right) if len(right) > 0 else 0.0\n",
    "\n",
    "    return parent_var - (w_left * left_var + w_right * right_var)\n",
    "\n",
    "\n",
    "def mse(y_hat: NDArray[np.floating[Any]], y: NDArray[np.floating[Any]]) -> np.floating[Any]:\n",
    "    return np.average((y_hat - y) ** 2)\n",
    "\n",
    "\n",
    "def get_mean_value(y: np.ndarray) -> np.floating:\n",
    "    return np.average(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed = np.random.default_rng(seed=0)\n",
    "X_reg = rng_seed.random(size=(100, 10))\n",
    "y_reg = np.sum(X_reg ** 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(X_reg.shape)\n",
    "print(y_reg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree = build_tree(X_reg, y_reg, variance_gain, get_mean_value, max_height=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{f: 4, v: 0.8784579289518393, left: {f: 7, v: 0.7731027147673438, left: {f: 0, v: 0.8595724184235947, left: {f: None, v: 6.585205450572977, left: None, right: None}, right: {f: None, v: 5.5910333769445035, left: None, right: None}}, right: {f: 0, v: 0.21342352557953748, left: {f: None, v: 4.621060382833744, left: None, right: None}, right: {f: None, v: 3.8588176735664836, left: None, right: None}}}, right: {f: 9, v: 0.8338161758058992, left: {f: 1, v: 0.8479934402366498, left: {f: None, v: 5.241748979841595, left: None, right: None}, right: {f: None, v: 3.803558756762245, left: None, right: None}}, right: {f: 3, v: 0.760264000981916, left: {f: None, v: 4.002968667852741, left: None, right: None}, right: {f: None, v: 3.078938332071388, left: None, right: None}}}}\n"
     ]
    }
   ],
   "source": [
    "print(reg_tree.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error of prediction: 0.3377934989274023\n"
     ]
    }
   ],
   "source": [
    "y_hat = np.asarray([reg_tree.predict(X_reg[i]) for i in range(X_reg.shape[0])])\n",
    "\n",
    "print(f'mean squared error of prediction: {mse(y_hat, y_reg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_forest(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    cost_fn: Callable[[np.ndarray, np.ndarray, np.ndarray, np.ndarray], float],\n",
    "    compute_leaf: Callable[[np.ndarray], np.number],\n",
    "    tree_height: int,\n",
    "    num_features: int | None = None,\n",
    "    num_trees: int = 100,\n",
    ") -> List[DecisionTree]:\n",
    "\n",
    "    forest = []\n",
    "\n",
    "    for _ in range(num_trees):\n",
    "        sampled_idx = rng_seed.integers(0, X.shape[0], size=X.shape[0])\n",
    "        tree = build_tree(\n",
    "            X[sampled_idx],\n",
    "            y[sampled_idx],\n",
    "            cost_fn,\n",
    "            compute_leaf,\n",
    "            max_height=tree_height,\n",
    "            num_features=num_features,\n",
    "            rng_seed=0\n",
    "        )\n",
    "        forest.append(tree)\n",
    "    \n",
    "\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = build_forest(X_reg, y_reg, variance_gain, get_mean_value, tree_height=3, num_trees=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X: np.ndarray, trees: List[DecisionTree], voting_strategy: Callable[[np.ndarray], np.number]) -> np.ndarray:\n",
    "    predictions = list()\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        votes = np.asarray([tree.predict(X[i]) for tree in trees])\n",
    "        prediction = voting_strategy(votes)\n",
    "\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return np.asarray(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error of prediction: 0.2273120061819379\n"
     ]
    }
   ],
   "source": [
    "y_hat = predict(X_reg, forest, get_mean_value)\n",
    "\n",
    "print(f'mean squared error of prediction: {mse(y_hat, y_reg)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coursera-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
